{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/shared/hltdir1/disk1/home/max/code/umls-embeddings/python\n",
      "\u001b[0m\u001b[01;34mbin\u001b[0m/  \u001b[01;34mdata\u001b[0m/  \u001b[01;34meukg\u001b[0m/  __init__.py  \u001b[01;34m__pycache__\u001b[0m/  results.txt  Untitled.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "%cd ~/code/umls-embeddings/python\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eukg.tf_util import Trainer, ModelSaver\n",
    "\n",
    "from eukg.emb import EmbeddingModel\n",
    "from eukg.gan import Generator, train_gan, Discriminator, DisGen\n",
    "from eukg import Config\n",
    "from eukg.data import data_util, DataGenerator, TfDataGenerator\n",
    "from eukg.emb import AceModel\n",
    "from eukg.tf_util import checkpoint_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestConfig:\n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    "config = TestConfig()\n",
    "config.val_proportion = 0.1\n",
    "config.embedding_size = 50\n",
    "config.energy_norm_ord = 1\n",
    "config.seed = 1337\n",
    "config.mode = 'disgen'\n",
    "config.model = 'transd-distmult'\n",
    "config.run_name = 'transd-dm-disgen-ace-7'\n",
    "config.ace_model = True\n",
    "config.no_semantic_network = True\n",
    "config.train_bert = False\n",
    "config.learning_rate = 1e-5\n",
    "config.batch_size = 16\n",
    "config.val_batch_size = 16\n",
    "config.num_epochs = 100\n",
    "config.data_dir = '/users/max/data/artifacts/umls-embeddings'\n",
    "config.secondary_data_dir = '/users/max/data/artifacts/umls-embeddings-compressed'\n",
    "config.model_dir = '/users/max/data/models/umls-embeddings'\n",
    "config.summaries_dir = '/shared/hltdir4/disk1/max/logs'\n",
    "config.eval_mode = 'save'\n",
    "config.eval_dir = '/users/max/data/artifacts/umls-embeddings'\n",
    "config.load = True\n",
    "config.num_workers = 6\n",
    "config.buffer_size = 1\n",
    "config.gpu_memory_growth = True\n",
    "config.num_generator_samples = 30\n",
    "config.lm_encoder_size = 768\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = config.seed\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# init model dir\n",
    "all_models_dir = config.model_dir\n",
    "config.model_dir = os.path.join(config.model_dir, config.model, config.run_name)\n",
    "if not os.path.exists(config.model_dir):\n",
    "  os.makedirs(config.model_dir)\n",
    "\n",
    "# init summaries dir\n",
    "config.summaries_dir = os.path.join(config.summaries_dir, config.run_name)\n",
    "if not os.path.exists(config.summaries_dir):\n",
    "  os.makedirs(config.summaries_dir)\n",
    "\n",
    "# load data\n",
    "cui2id, data, train_idx, val_idx = data_util.load_metathesaurus_data(config.data_dir, config.val_proportion)\n",
    "config.val_progress_update_interval = int(math.floor(float(len(val_idx)) / config.val_batch_size))\n",
    "config.batches_per_epoch = int(math.floor(float(len(train_idx)) / config.batch_size))\n",
    "if not config.no_semantic_network:\n",
    "  type2cuis = data_util.load_semantic_network_data(config.data_dir, data)\n",
    "else:\n",
    "  type2cuis = None\n",
    "\n",
    "data_generator = TfDataGenerator.TfDataGenerator(\n",
    "  data,\n",
    "  train_idx,\n",
    "  val_idx,\n",
    "  config.data_dir,\n",
    "  config.secondary_data_dir,\n",
    "  config.num_generator_samples,\n",
    "  config.batch_size,\n",
    "  config.num_epochs,\n",
    "  config.lm_encoder_size,\n",
    "  config.num_workers,\n",
    "  config.buffer_size\n",
    ")\n",
    "\n",
    "if config.gpu_memory_growth:\n",
    "  gpu_config = tf.ConfigProto()\n",
    "  gpu_config.gpu_options.allow_growth = True\n",
    "else:\n",
    "  gpu_config = None\n",
    "\n",
    "session = tf.Session(config=gpu_config)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1228 21:00:53.533342 140252633818944 deprecation_wrapper.py:119] From /shared/hltdir1/disk1/home/max/code/umls-embeddings/python/eukg/data/TfDataGenerator.py:72: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1228 21:00:53.899137 140252633818944 deprecation_wrapper.py:119] From /shared/hltdir1/disk1/home/max/code/umls-embeddings/python/eukg/data/TfDataGenerator.py:230: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
      "\n",
      "W1228 21:00:54.007996 140252633818944 deprecation.py:323] From /users/max/miniconda3/envs/tf-1.14/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, ?, 768)\n",
      "(?, ?)\n",
      "(?, ?)\n",
      "(?, ?, ?, 768)\n",
      "(?, ?)\n",
      "(?, ?, ?, 768)\n",
      "(?, ?)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1228 21:00:54.227475 140252633818944 deprecation.py:323] From /shared/hltdir1/disk1/home/max/code/umls-embeddings/python/eukg/data/TfDataGenerator.py:393: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n"
     ]
    }
   ],
   "source": [
    "dg = data_generator\n",
    "dg.create_iterator()\n",
    "\n",
    "subjs_emb = dg.subjs_emb\n",
    "rels_emb = dg.rels_emb\n",
    "objs_emb = dg.objs_emb\n",
    "nsubjs_embs = dg.nsubjs_embs\n",
    "nobjs_embs = dg.nobjs_embs\n",
    "\n",
    "subjs_lengths = dg.subjs_lengths\n",
    "rels_lengths = dg.rels_lengths\n",
    "objs_lengths = dg.objs_lengths\n",
    "nsubjs_lengths = dg.nsubjs_lengths\n",
    "nobjs_lengths = dg.nobjs_lengths\n",
    "\n",
    "neg_shape = tf.shape(nsubjs_embs)\n",
    "bsize, nsamples, seq_len = neg_shape[0], neg_shape[1], neg_shape[2]\n",
    "total_neg_size = bsize * nsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg.load_train(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = session.run([dg.subjs_lengths, dg.rels_lengths, dg.objs_lengths, dg.nsubjs_lengths, dg.nobjs_lengths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " 5,\n",
       " 10,\n",
       " [(5, 10),\n",
       "  (31, 10),\n",
       "  (11, 10),\n",
       "  (8, 10),\n",
       "  (9, 10),\n",
       "  (4, 10),\n",
       "  (10, 10),\n",
       "  (5, 10),\n",
       "  (9, 10),\n",
       "  (15, 10),\n",
       "  (9, 10),\n",
       "  (7, 10),\n",
       "  (8, 10),\n",
       "  (3, 10),\n",
       "  (16, 10),\n",
       "  (3, 25),\n",
       "  (3, 31),\n",
       "  (3, 31),\n",
       "  (3, 12),\n",
       "  (3, 15),\n",
       "  (3, 6),\n",
       "  (3, 7),\n",
       "  (3, 8),\n",
       "  (3, 11),\n",
       "  (3, 16),\n",
       "  (3, 17),\n",
       "  (3, 14),\n",
       "  (3, 7),\n",
       "  (3, 13),\n",
       "  (3, 6)])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl, rl, ol, nsl, nol = f\n",
    "b_idx = 2\n",
    "ex = sl[b_idx], rl[b_idx], ol[b_idx], list(zip(nsl[b_idx], nol[b_idx]))\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
